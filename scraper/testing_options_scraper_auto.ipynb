{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Options Scraper with Automated Login - FIXED VERSION\n",
    "\n",
    "This notebook fixes the table reading issues in the original scraper:\n",
    "1. Better detection between active trades vs closed trade perspectives\n",
    "2. Improved table finding logic for Bull Put strategies\n",
    "3. Enhanced debugging output to identify which tables are being scraped\n",
    "\n",
    "## Setup Requirements\n",
    "\n",
    "1. Create a credentials file `credentials.txt` in the same directory with format:\n",
    "   ```\n",
    "   username:your_username_or_email\n",
    "   password:your_password\n",
    "   ```\n",
    "\n",
    "2. Add `credentials.txt` to your `.gitignore` file to keep credentials secure.\n",
    "\n",
    "3. The browser session will remain logged in after the script completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credentials(credentials_file='credentials.txt'):\n",
    "    \"\"\"\n",
    "    Load username and password from credentials file\n",
    "    \n",
    "    Parameters:\n",
    "    credentials_file (str): Path to credentials file\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (username, password) or (None, None) if file not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(credentials_file):\n",
    "            print(f\"Credentials file '{credentials_file}' not found.\")\n",
    "            print(\"Please create a file with format:\")\n",
    "            print(\"username:your_username_or_email\")\n",
    "            print(\"password:your_password\")\n",
    "            return None, None\n",
    "        \n",
    "        username = None\n",
    "        password = None\n",
    "        \n",
    "        with open(credentials_file, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith('username:'):\n",
    "                    username = line.split('username:', 1)[1].strip()\n",
    "                elif line.startswith('password:'):\n",
    "                    password = line.split('password:', 1)[1].strip()\n",
    "        \n",
    "        if not username or not password:\n",
    "            print(\"Invalid credentials file format. Expected:\")\n",
    "            print(\"username:your_username_or_email\")\n",
    "            print(\"password:your_password\")\n",
    "            return None, None\n",
    "        \n",
    "        return username, password\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading credentials file: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_login(driver, username, password, max_retries=3):\n",
    "    \"\"\"\n",
    "    Perform automated login to optionrecom.com\n",
    "    \n",
    "    Parameters:\n",
    "    driver: Selenium WebDriver instance\n",
    "    username (str): Username or email\n",
    "    password (str): Password\n",
    "    max_retries (int): Maximum number of login attempts\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if login successful, False otherwise\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Login attempt {attempt + 1} of {max_retries}...\")\n",
    "            \n",
    "            # Navigate to login page\n",
    "            driver.get(\"https://optionrecom.com/my-account-2/\")\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # Wait for and find username field\n",
    "            username_field = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, \"username\"))\n",
    "            )\n",
    "            \n",
    "            # Clear and enter username\n",
    "            username_field.clear()\n",
    "            username_field.send_keys(username)\n",
    "            print(\"Username entered successfully\")\n",
    "            \n",
    "            # Find and enter password\n",
    "            password_field = driver.find_element(By.NAME, \"password\")\n",
    "            password_field.clear()\n",
    "            password_field.send_keys(password)\n",
    "            print(\"Password entered successfully\")\n",
    "            \n",
    "            # Find and click login button\n",
    "            login_button = driver.find_element(By.XPATH, \"//button[@name='login']\")\n",
    "            login_button.click()\n",
    "            print(\"Login button clicked\")\n",
    "            \n",
    "            # Wait for page to load and check if login was successful\n",
    "            time.sleep(5)\n",
    "            \n",
    "            # Check if we're still on the login page (indicates failed login)\n",
    "            current_url = driver.current_url\n",
    "            if \"my-account\" in current_url and \"login\" not in current_url.lower():\n",
    "                print(\"Login successful!\")\n",
    "                return True\n",
    "            \n",
    "            # Check for error messages\n",
    "            error_elements = driver.find_elements(By.CSS_SELECTOR, \".woocommerce-error, .error, [class*='error']\")\n",
    "            if error_elements:\n",
    "                error_text = error_elements[0].text\n",
    "                print(f\"Login failed: {error_text}\")\n",
    "            else:\n",
    "                print(\"Login may have failed - still on login page\")\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout on attempt {attempt + 1} - page took too long to load\")\n",
    "        except NoSuchElementException as e:\n",
    "            print(f\"Could not find login element on attempt {attempt + 1}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error on attempt {attempt + 1}: {str(e)}\")\n",
    "        \n",
    "        if attempt < max_retries - 1:\n",
    "            print(f\"Retrying in 3 seconds...\")\n",
    "            time.sleep(3)\n",
    "    \n",
    "    print(f\"Login failed after {max_retries} attempts\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_database(db_path='../database/option_strategies.db'):\n",
    "    \"\"\"Connect to the SQLite database\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Verify the database has the required table\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='option_strategies'\")\n",
    "        if not cursor.fetchone():\n",
    "            print(f\"Error: Database {db_path} does not contain the option_strategies table.\")\n",
    "            print(\"Please run the database setup script first.\")\n",
    "            conn.close()\n",
    "            return None, None\n",
    "            \n",
    "        return conn, cursor\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to database: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(driver):\n",
    "    \"\"\"Extract the date from the page\"\"\"\n",
    "    try:\n",
    "        # Search the page text\n",
    "        page_text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        date_pattern = r'(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d+\\w*,\\s+\\d{4}'\n",
    "        matches = re.findall(date_pattern, page_text)\n",
    "        \n",
    "        if matches:\n",
    "            return matches[0]\n",
    "        \n",
    "        return \"Date not found\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting date: {str(e)}\")\n",
    "        return \"Date extraction error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_options_expiry_date(driver, tab_content=None):\n",
    "    \"\"\"Extract the Options Expiry Date\"\"\"\n",
    "    try:\n",
    "        # Search entire page\n",
    "        page_text = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        date_match = re.search(r'Options Expiry Date:?\\s*(\\d{4}-\\d{2}-\\d{2})', page_text)\n",
    "        if date_match:\n",
    "            return date_match.group(1)\n",
    "        \n",
    "        # More general search\n",
    "        date_match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', page_text)\n",
    "        if date_match:\n",
    "            return date_match.group(1)\n",
    "        \n",
    "        return \"Expiry date not found\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting options expiry date: {str(e)}\")\n",
    "        return \"Expiry date extraction error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_active_trades_table(table):\n",
    "    \"\"\"Check if a table contains active trades (not closed trade perspectives)\"\"\"\n",
    "    try:\n",
    "        # Get table text to check for closed trade indicators\n",
    "        table_text = table.text.lower()\n",
    "        \n",
    "        # Look for indicators of closed trades\n",
    "        closed_indicators = [\n",
    "            'closed trade perspectives',\n",
    "            'historical',\n",
    "            'past performance',\n",
    "            'expired',\n",
    "            'completed'\n",
    "        ]\n",
    "        \n",
    "        # Check if any closed indicators are present\n",
    "        for indicator in closed_indicators:\n",
    "            if indicator in table_text:\n",
    "                return False\n",
    "        \n",
    "        # Check the parent container for closed trade indicators\n",
    "        parent_elements = []\n",
    "        current = table\n",
    "        for _ in range(3):  # Check up to 3 levels up\n",
    "            try:\n",
    "                current = current.find_element(By.XPATH, '..')\n",
    "                parent_elements.append(current)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        for parent in parent_elements:\n",
    "            try:\n",
    "                parent_text = parent.text.lower()\n",
    "                for indicator in closed_indicators:\n",
    "                    if indicator in parent_text:\n",
    "                        return False\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking if table is active trades: {str(e)}\")\n",
    "        return True  # Default to True if we can't determine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_table_in_tab(driver, tab_content):\n",
    "    \"\"\"Find the best table within a tab, prioritizing active trades\"\"\"\n",
    "    tables = []\n",
    "    \n",
    "    # First try to find tables within the tab content\n",
    "    if tab_content:\n",
    "        try:\n",
    "            tables_in_tab = tab_content.find_elements(By.TAG_NAME, \"table\")\n",
    "            tables.extend(tables_in_tab)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # If no tables in tab content, look for visible tables on the page\n",
    "    if not tables:\n",
    "        all_tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "        visible_tables = [t for t in all_tables if t.is_displayed()]\n",
    "        tables = visible_tables\n",
    "    \n",
    "    if not tables:\n",
    "        return None\n",
    "    \n",
    "    # Filter for active trades tables and tables with data\n",
    "    best_table = None\n",
    "    best_score = -1\n",
    "    \n",
    "    for table in tables:\n",
    "        try:\n",
    "            # Check if table has data rows\n",
    "            rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            data_rows = [r for r in rows[1:] if r.find_elements(By.TAG_NAME, \"td\")]  # Skip header\n",
    "            \n",
    "            if not data_rows:\n",
    "                continue\n",
    "            \n",
    "            score = len(data_rows)  # Base score on number of data rows\n",
    "            \n",
    "            # Prioritize active trades tables\n",
    "            if is_active_trades_table(table):\n",
    "                score += 1000  # Big bonus for active trades\n",
    "            \n",
    "            # Check if table has expected columns\n",
    "            headers = table.find_elements(By.TAG_NAME, \"th\")\n",
    "            header_texts = [h.text.upper() for h in headers]\n",
    "            \n",
    "            expected_columns = ['TICKER', 'SYMBOL', 'TRIGGER', 'STRIKE', 'PREMIUM']\n",
    "            column_matches = sum(1 for col in expected_columns if any(col in h for h in header_texts))\n",
    "            score += column_matches * 10\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_table = table\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating table: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return best_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_data(driver, tab, tab_index, date_info, strategy_type, conn, cursor):\n",
    "    \"\"\"Extract data from the table in the current tab and save to database - FIXED VERSION\"\"\"\n",
    "    try:\n",
    "        tab_name = tab.text.strip().replace('\\n', ' ')\n",
    "        print(f\"\\nProcessing Tab {tab_index+1}: '{tab_name}'\")\n",
    "        \n",
    "        # Click the tab\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", tab)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        try:\n",
    "            tab.click()\n",
    "        except:\n",
    "            driver.execute_script(\"arguments[0].click();\", tab)\n",
    "        \n",
    "        time.sleep(3)  # Give more time for content to load\n",
    "        \n",
    "        # Find tab content\n",
    "        tab_href = tab.get_attribute(\"href\")\n",
    "        tab_content = None\n",
    "        \n",
    "        if tab_href and \"#\" in tab_href:\n",
    "            tab_id = tab_href.split(\"#\")[1]\n",
    "            try:\n",
    "                tab_content = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.ID, tab_id))\n",
    "                )\n",
    "                print(f\"Found tab content for ID: {tab_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not find tab content for ID {tab_id}: {str(e)}\")\n",
    "        \n",
    "        # Extract options expiry date\n",
    "        options_expiry_date = extract_options_expiry_date(driver, tab_content)\n",
    "        \n",
    "        # Find the best table for this tab\n",
    "        table = find_best_table_in_tab(driver, tab_content)\n",
    "        \n",
    "        if not table:\n",
    "            print(f\"No suitable tables found in tab #{tab_index+1}\")\n",
    "            return 0\n",
    "        \n",
    "        # Check if this is an active trades table\n",
    "        is_active = is_active_trades_table(table)\n",
    "        print(f\"Table type: {'Active trades' if is_active else 'Closed/Historical trades'}\")\n",
    "        \n",
    "        if not is_active:\n",
    "            print(f\"Skipping closed trade perspectives table in tab #{tab_index+1}\")\n",
    "            return 0\n",
    "        \n",
    "        # Extract headers\n",
    "        headers = table.find_elements(By.TAG_NAME, \"th\")\n",
    "        header_texts = [header.text.strip() for header in headers]\n",
    "        print(f\"Table headers: {header_texts}\")\n",
    "        \n",
    "        # Find column indices with improved matching\n",
    "        column_map = {\n",
    "            'ID': -1,\n",
    "            'Ticker': -1,\n",
    "            'Trigger Price': -1,\n",
    "            'Strike Price': -1,\n",
    "            'Estimated Premium': -1\n",
    "        }\n",
    "        \n",
    "        for i, header in enumerate(header_texts):\n",
    "            h_upper = header.upper()\n",
    "            if 'ID' in h_upper and column_map['ID'] == -1:\n",
    "                column_map['ID'] = i\n",
    "            elif ('TICKER' in h_upper or 'SYMBOL' in h_upper) and column_map['Ticker'] == -1:\n",
    "                column_map['Ticker'] = i\n",
    "            elif ('TRIGGER' in h_upper and 'PRICE' in h_upper) or 'ENTRY' in h_upper and column_map['Trigger Price'] == -1:\n",
    "                column_map['Trigger Price'] = i\n",
    "            elif 'STRIKE' in h_upper and 'PRICE' in h_upper and column_map['Strike Price'] == -1:\n",
    "                column_map['Strike Price'] = i\n",
    "            elif ('PREMIUM' in h_upper or 'ESTIMATED' in h_upper) and column_map['Estimated Premium'] == -1:\n",
    "                column_map['Estimated Premium'] = i\n",
    "        \n",
    "        print(f\"Column mapping: {column_map}\")\n",
    "        \n",
    "        # Extract rows\n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")[1:]  # Skip header\n",
    "        records_count = 0\n",
    "        \n",
    "        print(f\"Found {len(rows)} data rows\")\n",
    "        \n",
    "        for row_idx, row in enumerate(rows):\n",
    "            try:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if not cells:\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Row {row_idx + 1}: {len(cells)} cells\")\n",
    "                \n",
    "                # Extract data from cells with bounds checking\n",
    "                item_id = cells[column_map['ID']].text.strip() if column_map['ID'] != -1 and column_map['ID'] < len(cells) else f\"AUTO_{row_idx+1}\"\n",
    "                ticker_raw = cells[column_map['Ticker']].text.strip() if column_map['Ticker'] != -1 and column_map['Ticker'] < len(cells) else 'N/A'\n",
    "\n",
    "                # Check if ticker contains (ER) and process accordingly\n",
    "                er_value = 0\n",
    "                if \"(ER)\" in ticker_raw:\n",
    "                    ticker = ticker_raw.replace(\"(ER)\", \"\").strip()\n",
    "                    er_value = 1\n",
    "                else:\n",
    "                    ticker = ticker_raw\n",
    "\n",
    "                # Skip records with invalid ticker values\n",
    "                if not ticker or ticker.lower() in ['n/a', 'none', '', 'null']:\n",
    "                    print(f\"Skipping row {row_idx + 1} - invalid ticker: '{ticker}'\")\n",
    "                    continue\n",
    "\n",
    "                trigger_price = cells[column_map['Trigger Price']].text.strip() if column_map['Trigger Price'] != -1 and column_map['Trigger Price'] < len(cells) else 'N/A'\n",
    "                strike_price = cells[column_map['Strike Price']].text.strip() if column_map['Strike Price'] != -1 and column_map['Strike Price'] < len(cells) else 'N/A'\n",
    "                estimated_premium = cells[column_map['Estimated Premium']].text.strip() if column_map['Estimated Premium'] != -1 and column_map['Estimated Premium'] < len(cells) else 'N/A'\n",
    "\n",
    "                # Parse 'strike_price' to extract 'buy' and 'sell' values\n",
    "                strike_buy_value, strike_sell_value = 0.0, 0.0\n",
    "                if \" - \" in strike_price:\n",
    "                    parts = strike_price.split(\" - \")\n",
    "                    if len(parts) == 2:\n",
    "                        try:\n",
    "                            strike_sell_part = parts[0].strip()\n",
    "                            strike_buy_part = parts[1].strip()\n",
    "\n",
    "                            # Extract numerical values more robustly\n",
    "                            sell_match = re.search(r'(\\d+\\.?\\d*)', strike_sell_part)\n",
    "                            buy_match = re.search(r'(\\d+\\.?\\d*)', strike_buy_part)\n",
    "                            \n",
    "                            if sell_match:\n",
    "                                strike_sell_value = float(sell_match.group(1))\n",
    "                            if buy_match:\n",
    "                                strike_buy_value = float(buy_match.group(1))\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Error parsing strike prices: {str(e)}\")\n",
    "\n",
    "                print(f\"Processing: {ticker} | Trigger: {trigger_price} | Strike: {strike_price} | Premium: {estimated_premium}\")\n",
    "                \n",
    "                # Database insert\n",
    "                cursor.execute('''\n",
    "                INSERT INTO option_strategies (\n",
    "                    scrape_date, strategy_type, tab_name, ticker, trigger_price, \n",
    "                    strike_price, strike_buy, strike_sell, estimated_premium, item_id, options_expiry_date, date_info, er\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                ''', (\n",
    "                    datetime.now().isoformat(), strategy_type, tab_name, ticker, trigger_price, \n",
    "                    strike_price, strike_buy_value, strike_sell_value, estimated_premium, item_id, options_expiry_date, date_info, er_value\n",
    "                ))\n",
    "\n",
    "                conn.commit()\n",
    "                records_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {row_idx + 1}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"Successfully saved {records_count} records from tab #{tab_index+1}\")\n",
    "        return records_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tab #{tab_index+1}: {str(e)}\")\n",
    "        import traceback\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_strategy_page(driver, strategy_url, strategy_type, conn, cursor):\n",
    "    \"\"\"Process a single strategy page and extract data from all tabs\"\"\"\n",
    "    try:\n",
    "        print(f\"\\n===== Processing {strategy_type} Strategy Page =====\")\n",
    "        driver.get(strategy_url)\n",
    "        time.sleep(5)  # Give more time for page to load\n",
    "        \n",
    "        # Extract the date\n",
    "        date_info = extract_date(driver)\n",
    "        print(f\"Page date: {date_info}\")\n",
    "        \n",
    "        # Find all tabs using multiple methods\n",
    "        tabs = []\n",
    "        tab_selectors = [\n",
    "            \"//div[contains(@class, 'ep_tabs_header')]//a[contains(@class, 'ep_label_main')]\",\n",
    "            \"//a[contains(@class, 'ep_label_main')]\",\n",
    "            \"//div[contains(@class, 'tabs')]//a\",\n",
    "            \"//ul[contains(@class, 'tabs')]//a\",\n",
    "            \"//div[contains(@class, 'tab')]//a\"\n",
    "        ]\n",
    "        \n",
    "        for selector in tab_selectors:\n",
    "            try:\n",
    "                found_tabs = driver.find_elements(By.XPATH, selector)\n",
    "                if found_tabs:\n",
    "                    tabs = found_tabs\n",
    "                    print(f\"Found {len(tabs)} tabs using selector: {selector}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Selector {selector} failed: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not tabs:\n",
    "            print(f\"No tab elements found on the {strategy_type} page\")\n",
    "            # Try to process any tables found on the page\n",
    "            tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "            if tables:\n",
    "                print(f\"Found {len(tables)} tables without tabs, attempting to process...\")\n",
    "                # Create a dummy tab for processing\n",
    "                class DummyTab:\n",
    "                    def __init__(self, index):\n",
    "                        self.index = index\n",
    "                    def text(self):\n",
    "                        return f\"Table {self.index + 1}\"\n",
    "                    def get_attribute(self, attr):\n",
    "                        return None\n",
    "                    def click(self):\n",
    "                        pass\n",
    "                \n",
    "                dummy_tab = DummyTab(0)\n",
    "                return extract_table_data(driver, dummy_tab, 0, date_info, strategy_type, conn, cursor)\n",
    "            return 0\n",
    "        \n",
    "        # Print tab information\n",
    "        for i, tab in enumerate(tabs):\n",
    "            try:\n",
    "                tab_text = tab.text.strip().replace('\\n', ' ')\n",
    "                tab_href = tab.get_attribute('href')\n",
    "                print(f\"Tab {i+1}: '{tab_text}' -> {tab_href}\")\n",
    "            except:\n",
    "                print(f\"Tab {i+1}: Unable to get text/href\")\n",
    "        \n",
    "        # Process only the first 4 tabs\n",
    "        num_tabs_to_process = min(4, len(tabs))\n",
    "        total_records = 0\n",
    "        \n",
    "        for i, tab in enumerate(tabs[:num_tabs_to_process]):\n",
    "            records = extract_table_data(driver, tab, i, date_info, strategy_type, conn, cursor)\n",
    "            total_records += records\n",
    "            time.sleep(2)  # Small delay between tabs\n",
    "        \n",
    "        return total_records\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {strategy_type} strategy page: {str(e)}\")\n",
    "        import traceback\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_option_strategies_automated(db_path='../database/option_strategies.db', \n",
    "                                     browser_type=\"chrome\", \n",
    "                                     credentials_file='credentials.txt',\n",
    "                                     keep_browser_open=True):\n",
    "    \"\"\"\n",
    "    FIXED VERSION: Scrape data from option strategy pages with improved table detection\n",
    "    \n",
    "    Parameters:\n",
    "    db_path (str): Path to the SQLite database file\n",
    "    browser_type (str): 'chrome' or 'edge'\n",
    "    credentials_file (str): Path to credentials file\n",
    "    keep_browser_open (bool): Keep browser open after scraping to maintain session\n",
    "    \n",
    "    Returns:\n",
    "    int: Number of records added to the database\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load credentials\n",
    "    username, password = load_credentials(credentials_file)\n",
    "    if not username or not password:\n",
    "        return 0\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn, cursor = connect_to_database(db_path)\n",
    "    if not conn or not cursor:\n",
    "        return 0\n",
    "    \n",
    "    # Initialize browser with options to keep it open\n",
    "    chrome_options = ChromeOptions()\n",
    "    chrome_options.add_argument('--start-maximized')\n",
    "    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    if keep_browser_open:\n",
    "        # Add detach option to keep browser open\n",
    "        chrome_options.add_experimental_option(\"detach\", True)\n",
    "    \n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)\n",
    "    \n",
    "    try:\n",
    "        # Perform automated login\n",
    "        print(\"Starting automated login process...\")\n",
    "        if not automated_login(driver, username, password):\n",
    "            print(\"Login failed. Cannot proceed with scraping.\")\n",
    "            return 0\n",
    "        \n",
    "        print(\"Login successful! Proceeding with data scraping...\")\n",
    "        \n",
    "        # Define strategies to scrape\n",
    "        strategies = [\n",
    "            {\n",
    "                \"url\": \"https://optionrecom.com/bear-call-spread-strategy/\",\n",
    "                \"type\": \"Bear Call\"\n",
    "            },\n",
    "            {\n",
    "                \"url\": \"https://optionrecom.com/bull-put-spread-strategy/\",\n",
    "                \"type\": \"Bull Put\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Process each strategy page\n",
    "        total_records = 0\n",
    "        \n",
    "        for strategy in strategies:\n",
    "            records = process_strategy_page(driver, strategy[\"url\"], strategy[\"type\"], conn, cursor)\n",
    "            total_records += records\n",
    "            time.sleep(3)  # Delay between strategy pages\n",
    "        \n",
    "        print(f\"\\nTotal records saved to database: {total_records}\")\n",
    "        \n",
    "        # Query to show what was saved\n",
    "        cursor.execute(\"SELECT strategy_type, tab_name, COUNT(*) as count FROM option_strategies WHERE scrape_date >= datetime('now', '-1 hour') GROUP BY strategy_type, tab_name\")\n",
    "        results = cursor.fetchall()\n",
    "        \n",
    "        print(\"\\nRecords by strategy and tab (last hour):\")\n",
    "        for strategy, tab, count in results:\n",
    "            print(f\"  {strategy} - {tab}: {count} records\")\n",
    "        \n",
    "        if keep_browser_open:\n",
    "            print(\"\\nBrowser session maintained. You can manually navigate to other pages.\")\n",
    "            print(\"Close the browser window when finished.\")\n",
    "        \n",
    "        return total_records\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        print(f\"Full traceback: {traceback.format_exc()}\")\n",
    "        return 0\n",
    "    finally:\n",
    "        if not keep_browser_open:\n",
    "            driver.quit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Fixed Scraper\n",
    "\n",
    "Execute the cell below to run the fixed automated scraper with improved table detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting automated login process...\n",
      "Login attempt 1 of 3...\n",
      "Username entered successfully\n",
      "Password entered successfully\n",
      "Login button clicked\n",
      "Login successful!\n",
      "Login successful! Proceeding with data scraping...\n",
      "\n",
      "===== Processing Bear Call Strategy Page =====\n",
      "Page date: August\n",
      "Found 8 tabs using selector: //div[contains(@class, 'ep_tabs_header')]//a[contains(@class, 'ep_label_main')]\n",
      "Tab 1: 'Mild Risk 95-97% accuracy > shorter expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__9f43ceed-3419-409f-bf35-d667ce0f5453\n",
      "Tab 2: 'Minimal Risk 97-99% accuracy > shorter expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__80047de2-1d95-4611-8895-f8f4215f316d\n",
      "Tab 3: 'Mild Risk 95-97% accuracy > longer expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__2fbffe4a-dd50-41e9-989f-b68347220373\n",
      "Tab 4: 'Minimal Risk 97-99% accuracy > longer expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__99187b37-b039-47f6-8c3b-7cb697ff6906\n",
      "Tab 5: 'Mild Risk 95-97% accuracy > shorter expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__6e26f72b-d240-4952-8b97-f044efd7338b\n",
      "Tab 6: 'Minimal Risk 97-99% accuracy > shorter expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__90455ead-1dba-43b6-8ddc-fdb8ebd26247\n",
      "Tab 7: 'Mild Risk 95-97% accuracy > longer expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__b86bf8bf-1984-48da-a92d-44b4cf4b1d84\n",
      "Tab 8: 'Minimal Risk 97-99% accuracy > longer expiry' -> https://optionrecom.com/bear-call-spread-strategy/#ep_tab_wrapper__9739aed3-8a0b-47a4-a4d6-98e775a0a9c6\n",
      "\n",
      "Processing Tab 1: 'Mild Risk 95-97% accuracy > shorter expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__9f43ceed-3419-409f-bf35-d667ce0f5453\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 2 data rows\n",
      "Row 1: 5 cells\n",
      "Processing: GOOGL | Trigger: 203.95 | Strike: sell 215.0 - buy 225.0 | Premium: 134\n",
      "Row 2: 5 cells\n",
      "Processing: UNH | Trigger: 257.65 | Strike: sell 280.0 - buy 290.0 | Premium: 100\n",
      "Successfully saved 2 records from tab #1\n",
      "\n",
      "Processing Tab 2: 'Minimal Risk 97-99% accuracy > shorter expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__80047de2-1d95-4611-8895-f8f4215f316d\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 1 data rows\n",
      "Row 1: 5 cells\n",
      "Skipping row 1 - invalid ticker: 'None'\n",
      "Successfully saved 0 records from tab #2\n",
      "\n",
      "Processing Tab 3: 'Mild Risk 95-97% accuracy > longer expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__2fbffe4a-dd50-41e9-989f-b68347220373\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 1 data rows\n",
      "Row 1: 5 cells\n",
      "Processing: UNH | Trigger: 258.88 | Strike: sell 275.0 - buy 285.0 | Premium: 179\n",
      "Successfully saved 1 records from tab #3\n",
      "\n",
      "Processing Tab 4: 'Minimal Risk 97-99% accuracy > longer expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__99187b37-b039-47f6-8c3b-7cb697ff6906\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 1 data rows\n",
      "Row 1: 5 cells\n",
      "Skipping row 1 - invalid ticker: 'None'\n",
      "Successfully saved 0 records from tab #4\n",
      "\n",
      "===== Processing Bull Put Strategy Page =====\n",
      "Page date: August\n",
      "Found 8 tabs using selector: //div[contains(@class, 'ep_tabs_header')]//a[contains(@class, 'ep_label_main')]\n",
      "Tab 1: 'Mild Risk 95-97% accuracy > shorter expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__4a859b84-f07b-41aa-99a2-7d6655abb52c\n",
      "Tab 2: 'Minimal Risk 97-99% accuracy > shorter expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__b5c618a8-e959-41e3-9d68-bc32ff8f6fa0\n",
      "Tab 3: 'Mild Risk 95-97% accuracy > longer expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__37d1f561-4feb-4c29-8bef-9ff5a9247b0f\n",
      "Tab 4: 'Minimal Risk 97-99% accuracy > longer expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__4f65188d-017d-4e06-9af2-7c46088c2b96\n",
      "Tab 5: 'Mild Risk 95-97% accuracy > shorter expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__192b5be8-6682-46e4-9d41-2f768d6e08da\n",
      "Tab 6: 'Minimal Risk 97-99% accuracy > shorter expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__6ac2b423-4c4b-4e04-b58d-5d5109067f52\n",
      "Tab 7: 'Mild Risk 95-97% accuracy > longer expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__03340ea2-e4fb-496c-b450-22102a1c05c2\n",
      "Tab 8: 'Minimal Risk 97-99% accuracy > longer expiry' -> https://optionrecom.com/bull-put-spread-strategy/#ep_tab_wrapper__841d44ba-8017-45f8-970d-e6accecaac5d\n",
      "\n",
      "Processing Tab 1: 'Mild Risk 95-97% accuracy > shorter expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__4a859b84-f07b-41aa-99a2-7d6655abb52c\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 1 data rows\n",
      "Row 1: 5 cells\n",
      "Processing: MSFT | Trigger: 513.61 | Strike: sell 485.0 - buy 475.0 | Premium: 78\n",
      "Successfully saved 1 records from tab #1\n",
      "\n",
      "Processing Tab 2: 'Minimal Risk 97-99% accuracy > shorter expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__b5c618a8-e959-41e3-9d68-bc32ff8f6fa0\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 1 data rows\n",
      "Row 1: 5 cells\n",
      "Skipping row 1 - invalid ticker: 'None'\n",
      "Successfully saved 0 records from tab #2\n",
      "\n",
      "Processing Tab 3: 'Mild Risk 95-97% accuracy > longer expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__37d1f561-4feb-4c29-8bef-9ff5a9247b0f\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 1 data rows\n",
      "Row 1: 5 cells\n",
      "Processing: TQQQ | Trigger: 81.68 | Strike: sell 78.0 - buy 70.0 | Premium: 159\n",
      "Successfully saved 1 records from tab #3\n",
      "\n",
      "Processing Tab 4: 'Minimal Risk 97-99% accuracy > longer expiry'\n",
      "Found tab content for ID: ep_tab_wrapper__4f65188d-017d-4e06-9af2-7c46088c2b96\n",
      "Table type: Active trades\n",
      "Table headers: ['ID', 'Ticker', 'Trigger Price', 'Strike Price', 'Estimated Premium']\n",
      "Column mapping: {'ID': 0, 'Ticker': 1, 'Trigger Price': 2, 'Strike Price': 3, 'Estimated Premium': 4}\n",
      "Found 2 data rows\n",
      "Row 1: 5 cells\n",
      "Processing: MSFT | Trigger: 511.98 | Strike: sell 485.0 - buy 475.0 | Premium: 96\n",
      "Row 2: 5 cells\n",
      "Processing: TSM | Trigger: 222.43 | Strike: sell 215.0 - buy 205.0 | Premium: 233\n",
      "Successfully saved 2 records from tab #4\n",
      "\n",
      "Total records saved to database: 7\n",
      "\n",
      "Records by strategy and tab (last hour):\n",
      "  Bear Call - Mild Risk 95-97% accuracy > longer expiry: 1 records\n",
      "  Bear Call - Mild Risk 95-97% accuracy > shorter expiry: 2 records\n",
      "  Bull Put - Mild Risk 95-97% accuracy > longer expiry: 1 records\n",
      "  Bull Put - Mild Risk 95-97% accuracy > shorter expiry: 1 records\n",
      "  Bull Put - Minimal Risk 97-99% accuracy > longer expiry: 2 records\n",
      "\n",
      "Browser session maintained. You can manually navigate to other pages.\n",
      "Close the browser window when finished.\n",
      "\n",
      "Testing scraper completed. Total records processed: 7\n"
     ]
    }
   ],
   "source": [
    "# Run the fixed automated scraper\n",
    "if __name__ == \"__main__\":\n",
    "    result = scrape_option_strategies_automated(\n",
    "        db_path='../database/option_strategies.db',\n",
    "        credentials_file='credentials.txt',\n",
    "        keep_browser_open=True  # Set to False if you want the browser to close automatically\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTesting scraper completed. Total records processed: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optcom3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
